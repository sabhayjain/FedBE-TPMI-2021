{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet for FedBE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy46_-wlEr5g",
        "outputId": "713097da-6001-44b6-fa09-a371f14d29a5"
      },
      "source": [
        "!pip install keras-swa==0.1.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-swa==0.1.5 in /usr/local/lib/python3.7/dist-packages (0.1.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wOBNu8TEu1A"
      },
      "source": [
        "from swa.keras import SWA\n",
        "import tensorflow.keras.backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stJrFfne1AtY"
      },
      "source": [
        "from keras.datasets import cifar10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8KlZ2ox1GwS"
      },
      "source": [
        "(trainX, trainy), (testX, testy) = cifar10.load_data()\n",
        "trainX = trainX/255\n",
        "testX = testX/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hI7kn4F14Uv"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "from imutils import paths\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0XVVFJt2P-u"
      },
      "source": [
        "lb = LabelBinarizer()\n",
        "trainy = lb.fit_transform(trainy)\n",
        "testy = lb.fit_transform(testy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "825_bYug4h01"
      },
      "source": [
        "def label_dict(img, labels):\n",
        "  lab_lis = {}\n",
        "  for i in range(10):\n",
        "    lab_lis[i] = []\n",
        "  data = list(zip(img, labels))\n",
        "  for im, lab in data:\n",
        "    idx = np.argmax(lab)\n",
        "    lab_lis[idx].append((im, lab))\n",
        "  return lab_lis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_J40L6C4jdf"
      },
      "source": [
        "t = label_dict(trainX, trainy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axv59HWr5w0e"
      },
      "source": [
        "unlab_data = []\n",
        "unlab_img_data = []\n",
        "for i in range(len(t)):\n",
        "  unlab_data.extend(t[i][4000:])\n",
        "for x,y in unlab_data:\n",
        "  unlab_img_data.append(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79bkiQUpE5ET",
        "outputId": "653700e8-e3a3-4165-b8d2-74f21e07f5f6"
      },
      "source": [
        "unlab_img_data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.99607843, 0.99607843, 0.99607843],\n",
              "        [0.98823529, 0.98823529, 0.98823529],\n",
              "        [0.98823529, 0.98823529, 0.98431373],\n",
              "        ...,\n",
              "        [0.98823529, 0.98823529, 0.99215686],\n",
              "        [0.98823529, 0.98823529, 0.98039216],\n",
              "        [1.        , 1.        , 0.99607843]],\n",
              "\n",
              "       [[1.        , 1.        , 1.        ],\n",
              "        [0.99607843, 0.99607843, 0.99607843],\n",
              "        [0.99607843, 0.99607843, 0.98823529],\n",
              "        ...,\n",
              "        [0.99607843, 0.99607843, 1.        ],\n",
              "        [0.99607843, 0.99607843, 0.98823529],\n",
              "        [1.        , 1.        , 1.        ]],\n",
              "\n",
              "       [[1.        , 1.        , 1.        ],\n",
              "        [0.99607843, 0.99607843, 0.99607843],\n",
              "        [1.        , 0.99607843, 0.99215686],\n",
              "        ...,\n",
              "        [0.99607843, 0.99607843, 1.        ],\n",
              "        [0.99607843, 0.99607843, 0.98823529],\n",
              "        [1.        , 1.        , 1.        ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.96862745, 0.94509804, 0.95294118],\n",
              "        [0.96078431, 0.93333333, 0.94117647],\n",
              "        [0.96470588, 0.9372549 , 0.9372549 ],\n",
              "        ...,\n",
              "        [0.96470588, 0.9372549 , 0.94509804],\n",
              "        [0.96470588, 0.9372549 , 0.94509804],\n",
              "        [0.96862745, 0.94901961, 0.95686275]],\n",
              "\n",
              "       [[0.68235294, 0.69803922, 0.67843137],\n",
              "        [0.69019608, 0.68235294, 0.67058824],\n",
              "        [0.70196078, 0.67843137, 0.67058824],\n",
              "        ...,\n",
              "        [0.68235294, 0.69019608, 0.69411765],\n",
              "        [0.6745098 , 0.69803922, 0.69019608],\n",
              "        [0.68627451, 0.70196078, 0.70196078]],\n",
              "\n",
              "       [[0.67843137, 0.71764706, 0.69019608],\n",
              "        [0.68235294, 0.69411765, 0.6745098 ],\n",
              "        [0.69411765, 0.68627451, 0.6745098 ],\n",
              "        ...,\n",
              "        [0.70588235, 0.83529412, 0.82352941],\n",
              "        [0.69411765, 0.83921569, 0.82352941],\n",
              "        [0.70196078, 0.84705882, 0.83921569]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIbri0xe79a2"
      },
      "source": [
        "client_names = [\"client_\"+str(i) for i in range(10)]\n",
        "client_data = {}\n",
        "for client in client_names:\n",
        "  client_data[client] = []\n",
        "i = 0\n",
        "for client in client_names:\n",
        "  client_data[client].extend(t[i%10][:1960])\n",
        "  client_data[client].extend(t[(i+1)%10][1960:3920])\n",
        "  i += 1\n",
        "for i in range(10):\n",
        "  k = 0\n",
        "  for j in range(10):\n",
        "    if j != (i)%10 and j != (i+1)%10:\n",
        "      client_data[\"client_\"+str(j)].extend(t[i][3920 + 10*k: 3920 + 10*(k+1)])\n",
        "      k += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQitzXbYCdZj"
      },
      "source": [
        "def batch(zip_data, batch_size = 40):\n",
        "  data, label = zip(*zip_data)\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
        "  return dataset.shuffle(len(label)).batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwMs6hlaC7xH"
      },
      "source": [
        "client_batched = {}\n",
        "for (name, data) in client_data.items():\n",
        "  client_batched[name] = batch(data)\n",
        "\n",
        "test_batched = tf.data.Dataset.from_tensor_slices((testX, testy)).batch(len(testy))\n",
        "unlab_dataset = tf.data.Dataset.from_tensor_slices((unlab_img_data)).batch(len(unlab_img_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5Lz3GrdGk6H"
      },
      "source": [
        "class MLP:\n",
        "    @staticmethod\n",
        "    def build():\n",
        "        tf_input = Input(shape=(32, 32,  3))\n",
        "        base_model = ResNet50(input_tensor=tf_input, include_top=False)\n",
        "        x = base_model.output\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "        x = Dense(1024, activation='relu')(x)\n",
        "        predictions = Dense(10, activation='softmax')(x)\n",
        "        model = Model(inputs=base_model.input, outputs=predictions)\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2eVLxQaKGEV"
      },
      "source": [
        "model = MLP()\n",
        "model = model.build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BmrbqbTKO37",
        "outputId": "379a4ea9-f967-4cbb-a345-779f3f467b0a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         2098176     global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           10250       dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 25,696,138\n",
            "Trainable params: 25,643,018\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BzZ4rWaLpN4",
        "outputId": "dde3b0c3-8317-45d6-8905-3f22ca60dfda"
      },
      "source": [
        "t = model.get_weights()\n",
        "for v in t:\n",
        "  print(np.shape(v))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7, 7, 3, 64)\n",
            "(64,)\n",
            "(64,)\n",
            "(64,)\n",
            "(64,)\n",
            "(64,)\n",
            "(1, 1, 64, 64)\n",
            "(64,)\n",
            "(64,)\n",
            "(64,)\n",
            "(64,)\n",
            "(64,)\n",
            "(3, 3, 64, 64)\n",
            "(64,)\n",
            "(64,)\n",
            "(64,)\n",
            "(64,)\n",
            "(64,)\n",
            "(1, 1, 64, 256)\n",
            "(256,)\n",
            "(1, 1, 64, 256)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(1, 1, 256, 64)\n",
            "(64,)\n",
            "(64,)\n",
            "(64,)\n",
            "(64,)\n",
            "(64,)\n",
            "(3, 3, 64, 64)\n",
            "(64,)\n",
            "(64,)\n",
            "(64,)\n",
            "(64,)\n",
            "(64,)\n",
            "(1, 1, 64, 256)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(1, 1, 256, 64)\n",
            "(64,)\n",
            "(64,)\n",
            "(64,)\n",
            "(64,)\n",
            "(64,)\n",
            "(3, 3, 64, 64)\n",
            "(64,)\n",
            "(64,)\n",
            "(64,)\n",
            "(64,)\n",
            "(64,)\n",
            "(1, 1, 64, 256)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(1, 1, 256, 128)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(3, 3, 128, 128)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(1, 1, 256, 512)\n",
            "(512,)\n",
            "(1, 1, 128, 512)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(1, 1, 512, 128)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(3, 3, 128, 128)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(1, 1, 128, 512)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(1, 1, 512, 128)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(3, 3, 128, 128)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(1, 1, 128, 512)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(1, 1, 512, 128)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(3, 3, 128, 128)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(1, 1, 128, 512)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(1, 1, 512, 256)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(3, 3, 256, 256)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(1, 1, 512, 1024)\n",
            "(1024,)\n",
            "(1, 1, 256, 1024)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1, 1, 1024, 256)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(3, 3, 256, 256)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(1, 1, 256, 1024)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1, 1, 1024, 256)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(3, 3, 256, 256)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(1, 1, 256, 1024)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1, 1, 1024, 256)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(3, 3, 256, 256)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(1, 1, 256, 1024)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1, 1, 1024, 256)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(3, 3, 256, 256)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(1, 1, 256, 1024)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1, 1, 1024, 256)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(3, 3, 256, 256)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(1, 1, 256, 1024)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1024,)\n",
            "(1, 1, 1024, 512)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(3, 3, 512, 512)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(1, 1, 1024, 2048)\n",
            "(2048,)\n",
            "(1, 1, 512, 2048)\n",
            "(2048,)\n",
            "(2048,)\n",
            "(2048,)\n",
            "(2048,)\n",
            "(2048,)\n",
            "(2048,)\n",
            "(2048,)\n",
            "(2048,)\n",
            "(2048,)\n",
            "(1, 1, 2048, 512)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(3, 3, 512, 512)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(1, 1, 512, 2048)\n",
            "(2048,)\n",
            "(2048,)\n",
            "(2048,)\n",
            "(2048,)\n",
            "(2048,)\n",
            "(1, 1, 2048, 512)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(3, 3, 512, 512)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(512,)\n",
            "(1, 1, 512, 2048)\n",
            "(2048,)\n",
            "(2048,)\n",
            "(2048,)\n",
            "(2048,)\n",
            "(2048,)\n",
            "(2048, 1024)\n",
            "(1024,)\n",
            "(1024, 10)\n",
            "(10,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4Sk-U_jKoTm"
      },
      "source": [
        "comms_round = 50\n",
        "loss='categorical_crossentropy'\n",
        "metrics = ['accuracy']\n",
        "optimizer = SGD(lr=0.01, \n",
        "                momentum=0.9\n",
        "               )   \n",
        "optimizer2 = SGD(lr=0.001,\n",
        "                 momentum=0.9\n",
        "               )   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYbxOUreCDai",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70931a87-145c-45b7-fe48-bf3721cec09b"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun May 16 16:13:29 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P0    33W /  70W |    478MiB / 15109MiB |      5%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rxt1ZYW77GRn"
      },
      "source": [
        "# model = MLP()\n",
        "# model = model.build()\n",
        "# model.compile(loss=loss, \n",
        "#                       optimizer=optimizer2, \n",
        "#                       metrics=metrics)\n",
        "# print((model.optimizer.lr))\n",
        "# model2 = MLP()\n",
        "# model2 = model2.build()\n",
        "# model2.compile(loss=loss, \n",
        "#                       optimizer=optimizer, \n",
        "#                       metrics=metrics)\n",
        "# print((model2.optimizer.lr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOd6IRXnKsL8"
      },
      "source": [
        "weight_scale = []\n",
        "for (name, data) in client_data.items():\n",
        "  weight_scale.append(len(data)/40000)\n",
        "weight_scale = np.array(weight_scale).reshape((len(weight_scale), 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCUMQ1SkLY_B"
      },
      "source": [
        "# def scale_model_weights(weight, scalar):\n",
        "#     weight_final = []\n",
        "#     steps = len(weight)\n",
        "#     for i in range(steps):\n",
        "#         weight_final.append(scalar * weight[i])\n",
        "#     return weight_final\n",
        "\n",
        "def sum_scaled_weights(scaled_weight_list, M, unlab_data):\n",
        "    #print(type(scaled_weight_list[0][0]))\n",
        "    temp = MLP()\n",
        "    model = temp.build()\n",
        "    p = np.zeros((10000,10))\n",
        "    for i in range(len(weight_scale)):\n",
        "      model.set_weights(scaled_weight_list[i])\n",
        "      p += model.predict(unlab_data)\n",
        "    avg_grad_mean = list()\n",
        "    avg_grad_var = list()\n",
        "    for grad_list_tuple in zip(*scaled_weight_list):\n",
        "        #print(np.shape(grad_list_tuple))\n",
        "        if len(np.shape(grad_list_tuple)) == 5:\n",
        "          w = weight_scale.reshape((len(weight_scale), 1, 1, 1, 1))\n",
        "        elif len(np.shape(grad_list_tuple)) == 4:\n",
        "          w = weight_scale.reshape((len(weight_scale), 1, 1, 1))\n",
        "        elif len(np.shape(grad_list_tuple)) == 3:\n",
        "          w = weight_scale.reshape((len(weight_scale), 1, 1))\n",
        "        else:\n",
        "          w = weight_scale\n",
        "        layer_mean = np.sum(grad_list_tuple*w, axis=0)\n",
        "        #print(np.shape(layer_mean))\n",
        "        layer_variance = np.sum(np.power(grad_list_tuple - layer_mean, 2)*w, axis = 0) \n",
        "        avg_grad_mean.append(layer_mean)\n",
        "        avg_grad_var.append(layer_variance)\n",
        "    model.set_weights(avg_grad_mean)\n",
        "    p += model.predict(unlab_data)\n",
        "    for i in range(M):\n",
        "      grad_list = list()\n",
        "      for j in range(len(avg_grad_var)):\n",
        "        grad_list.append(np.random.normal(avg_grad_mean[j], avg_grad_var[j]))\n",
        "      model.set_weights(grad_list)\n",
        "      p += model.predict(unlab_data)\n",
        "    return p/(M + len(weight_scale) + 1), avg_grad_mean\n",
        "\n",
        "\n",
        "def test_model(X_test, Y_test,  model, comm_round):\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    logits = model.predict(X_test)\n",
        "    loss = cce(Y_test, logits)\n",
        "    acc = accuracy_score(tf.argmax(logits, axis=1), tf.argmax(Y_test, axis=1))\n",
        "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n",
        "    return acc, loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuWKHJRgblNg"
      },
      "source": [
        "u_lab = np.stack(unlab_img_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-qxqDSFM3LS",
        "outputId": "1be9b871-23a8-4867-df8a-e9a93b58e71f"
      },
      "source": [
        "mlp_global = MLP()\n",
        "global_model = mlp_global.build()\n",
        "\n",
        "for comm_round in range(comms_round):\n",
        "            \n",
        "    \n",
        "    global_weights = global_model.get_weights()\n",
        "    \n",
        "    \n",
        "    scaled_local_weight_list = list()\n",
        "    client_names = list(client_batched.keys())\n",
        "    random.shuffle(client_names)\n",
        "    \n",
        "    for client in client_names:\n",
        "        def scheduler(epoch, lr):\n",
        "            if epoch  == 8:\n",
        "              lr = lr*0.1\n",
        "            if epoch == 15:\n",
        "              lr = lr*0.1  \n",
        "            return lr\n",
        "        mlp_local = MLP()\n",
        "        local_model = mlp_local.build()\n",
        "        local_model.compile(loss=loss, \n",
        "                      optimizer=SGD(lr=0.01,momentum=0.9), \n",
        "                      metrics=metrics)\n",
        "        local_model.set_weights(global_weights)\n",
        "        \n",
        "        callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "        local_model.fit(client_batched[client], epochs=5, verbose=0, callbacks=[callback])\n",
        "        scaled_local_weight_list.append(local_model.get_weights())\n",
        "        \n",
        "        K.clear_session()\n",
        "    p, avg = sum_scaled_weights(scaled_local_weight_list, 10, unlab_dataset)\n",
        "    p = p**2/(np.sum(p**2, axis = 1).reshape((len(p), 1)))\n",
        "\n",
        "    #lab_dataset = tf.data.Dataset.from_tensor_slices((unlab_img_data,p)).batch(128)\n",
        "    mlp_global = MLP()\n",
        "    global_model = mlp_global.build()\n",
        "    global_model.compile(loss=loss, \n",
        "                      optimizer=SGD(lr=0.001,momentum=0.9), \n",
        "                      metrics=metrics)\n",
        "    global_model.set_weights(avg)\n",
        "    swa = SWA(start_epoch=5, \n",
        "          lr_schedule='cyclic', \n",
        "          swa_lr=0.0004,\n",
        "          swa_lr2=0.001,\n",
        "          swa_freq=5,\n",
        "          batch_size=32,\n",
        "          verbose=0)\n",
        "    global_model.fit(u_lab, p, epochs = 10, verbose = 0, batch_size=128)\n",
        "\n",
        "    for(X_test, Y_test) in test_batched:\n",
        "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "comm_round: 0 | global_acc: 10.900% | global_loss: 2.3030264377593994\n",
            "comm_round: 1 | global_acc: 39.590% | global_loss: 2.2345852851867676\n",
            "comm_round: 2 | global_acc: 52.050% | global_loss: 2.1880578994750977\n",
            "comm_round: 3 | global_acc: 52.510% | global_loss: 2.170366048812866\n",
            "comm_round: 4 | global_acc: 56.500% | global_loss: 2.131707191467285\n",
            "comm_round: 5 | global_acc: 61.040% | global_loss: 2.115774631500244\n",
            "comm_round: 6 | global_acc: 60.010% | global_loss: 2.1074087619781494\n",
            "comm_round: 7 | global_acc: 64.590% | global_loss: 2.086677312850952\n",
            "comm_round: 8 | global_acc: 64.670% | global_loss: 2.09403133392334\n",
            "comm_round: 9 | global_acc: 65.580% | global_loss: 2.0810585021972656\n",
            "comm_round: 10 | global_acc: 65.400% | global_loss: 2.047136068344116\n",
            "comm_round: 11 | global_acc: 63.230% | global_loss: 2.0874855518341064\n",
            "comm_round: 12 | global_acc: 66.190% | global_loss: 2.0655770301818848\n",
            "comm_round: 13 | global_acc: 67.280% | global_loss: 2.0035312175750732\n",
            "comm_round: 14 | global_acc: 67.850% | global_loss: 2.0141258239746094\n",
            "comm_round: 15 | global_acc: 68.830% | global_loss: 2.030939817428589\n",
            "comm_round: 16 | global_acc: 67.930% | global_loss: 2.053110361099243\n",
            "comm_round: 17 | global_acc: 68.250% | global_loss: 2.022963285446167\n",
            "comm_round: 18 | global_acc: 68.770% | global_loss: 2.0050625801086426\n",
            "comm_round: 19 | global_acc: 68.790% | global_loss: 2.014329195022583\n",
            "comm_round: 20 | global_acc: 67.820% | global_loss: 2.0376951694488525\n",
            "comm_round: 21 | global_acc: 69.230% | global_loss: 2.016528844833374\n",
            "comm_round: 22 | global_acc: 68.290% | global_loss: 2.0155460834503174\n",
            "comm_round: 23 | global_acc: 69.050% | global_loss: 2.010066270828247\n",
            "comm_round: 24 | global_acc: 69.850% | global_loss: 1.977211356163025\n",
            "comm_round: 25 | global_acc: 68.880% | global_loss: 2.0193123817443848\n",
            "comm_round: 26 | global_acc: 68.760% | global_loss: 2.009416103363037\n",
            "comm_round: 27 | global_acc: 68.920% | global_loss: 2.00028395652771\n",
            "comm_round: 28 | global_acc: 70.020% | global_loss: 1.9681166410446167\n",
            "comm_round: 29 | global_acc: 69.630% | global_loss: 1.988830804824829\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PikWjnfCrOGH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}