{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yy46_-wlEr5g",
    "outputId": "d369feb2-fdb7-4537-b140-9f7c29f903ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-swa==0.1.5 in /usr/local/lib/python3.7/dist-packages (0.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-swa==0.1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6wOBNu8TEu1A"
   },
   "outputs": [],
   "source": [
    "from swa.tfkeras import SWA\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "stJrFfne1AtY"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "s8KlZ2ox1GwS"
   },
   "outputs": [],
   "source": [
    "(trainX, trainy), (testX, testy) = cifar10.load_data()\n",
    "trainX = trainX/255\n",
    "testX = testX/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9hI7kn4F14Uv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from imutils import paths\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_0XVVFJt2P-u"
   },
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "trainy = lb.fit_transform(trainy)\n",
    "testy = lb.fit_transform(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "825_bYug4h01"
   },
   "outputs": [],
   "source": [
    "def label_dict(img, labels):\n",
    "  lab_lis = {}\n",
    "  for i in range(10):\n",
    "    lab_lis[i] = []\n",
    "  data = list(zip(img, labels))\n",
    "  for im, lab in data:\n",
    "    idx = np.argmax(lab)\n",
    "    lab_lis[idx].append((im, lab))\n",
    "  return lab_lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2_J40L6C4jdf"
   },
   "outputs": [],
   "source": [
    "t = label_dict(trainX, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "axv59HWr5w0e"
   },
   "outputs": [],
   "source": [
    "unlab_data = []\n",
    "unlab_img_data = []\n",
    "for i in range(len(t)):\n",
    "  unlab_data.extend(t[i][4000:])\n",
    "for x,y in unlab_data:\n",
    "  unlab_img_data.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79bkiQUpE5ET",
    "outputId": "2ccdf79a-60f7-41e9-dbdd-b37a01464b5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.99607843, 0.99607843, 0.99607843],\n",
       "        [0.98823529, 0.98823529, 0.98823529],\n",
       "        [0.98823529, 0.98823529, 0.98431373],\n",
       "        ...,\n",
       "        [0.98823529, 0.98823529, 0.99215686],\n",
       "        [0.98823529, 0.98823529, 0.98039216],\n",
       "        [1.        , 1.        , 0.99607843]],\n",
       "\n",
       "       [[1.        , 1.        , 1.        ],\n",
       "        [0.99607843, 0.99607843, 0.99607843],\n",
       "        [0.99607843, 0.99607843, 0.98823529],\n",
       "        ...,\n",
       "        [0.99607843, 0.99607843, 1.        ],\n",
       "        [0.99607843, 0.99607843, 0.98823529],\n",
       "        [1.        , 1.        , 1.        ]],\n",
       "\n",
       "       [[1.        , 1.        , 1.        ],\n",
       "        [0.99607843, 0.99607843, 0.99607843],\n",
       "        [1.        , 0.99607843, 0.99215686],\n",
       "        ...,\n",
       "        [0.99607843, 0.99607843, 1.        ],\n",
       "        [0.99607843, 0.99607843, 0.98823529],\n",
       "        [1.        , 1.        , 1.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.96862745, 0.94509804, 0.95294118],\n",
       "        [0.96078431, 0.93333333, 0.94117647],\n",
       "        [0.96470588, 0.9372549 , 0.9372549 ],\n",
       "        ...,\n",
       "        [0.96470588, 0.9372549 , 0.94509804],\n",
       "        [0.96470588, 0.9372549 , 0.94509804],\n",
       "        [0.96862745, 0.94901961, 0.95686275]],\n",
       "\n",
       "       [[0.68235294, 0.69803922, 0.67843137],\n",
       "        [0.69019608, 0.68235294, 0.67058824],\n",
       "        [0.70196078, 0.67843137, 0.67058824],\n",
       "        ...,\n",
       "        [0.68235294, 0.69019608, 0.69411765],\n",
       "        [0.6745098 , 0.69803922, 0.69019608],\n",
       "        [0.68627451, 0.70196078, 0.70196078]],\n",
       "\n",
       "       [[0.67843137, 0.71764706, 0.69019608],\n",
       "        [0.68235294, 0.69411765, 0.6745098 ],\n",
       "        [0.69411765, 0.68627451, 0.6745098 ],\n",
       "        ...,\n",
       "        [0.70588235, 0.83529412, 0.82352941],\n",
       "        [0.69411765, 0.83921569, 0.82352941],\n",
       "        [0.70196078, 0.84705882, 0.83921569]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlab_img_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "EIbri0xe79a2"
   },
   "outputs": [],
   "source": [
    "client_names = [\"client_\"+str(i) for i in range(10)]\n",
    "client_data = {}\n",
    "for client in client_names:\n",
    "  client_data[client] = []\n",
    "i = 0\n",
    "for client in client_names:\n",
    "  client_data[client].extend(t[i%10][:1960])\n",
    "  client_data[client].extend(t[(i+1)%10][1960:3920])\n",
    "  i += 1\n",
    "for i in range(10):\n",
    "  k = 0\n",
    "  for j in range(10):\n",
    "    if j != (i)%10 and j != (i+1)%10:\n",
    "      client_data[\"client_\"+str(j)].extend(t[i][3920 + 10*k: 3920 + 10*(k+1)])\n",
    "      k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mQitzXbYCdZj"
   },
   "outputs": [],
   "source": [
    "def batch(zip_data, batch_size = 40):\n",
    "  data, label = zip(*zip_data)\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
    "  return dataset.shuffle(len(label)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "JwMs6hlaC7xH"
   },
   "outputs": [],
   "source": [
    "client_batched = {}\n",
    "for (name, data) in client_data.items():\n",
    "  client_batched[name] = batch(data)\n",
    "\n",
    "test_batched = tf.data.Dataset.from_tensor_slices((testX, testy)).batch(len(testy))\n",
    "unlab_dataset = tf.data.Dataset.from_tensor_slices((unlab_img_data)).batch(len(unlab_img_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "S5Lz3GrdGk6H"
   },
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    @staticmethod\n",
    "    def build():\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "        model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        model.add(AveragePooling2D((2, 2)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        model.add(AveragePooling2D((2, 2)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        model.add(AveragePooling2D((2, 2)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        model.add(AveragePooling2D((2, 2)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Q2eVLxQaKGEV"
   },
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "model = model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_BmrbqbTKO37",
    "outputId": "20c2a6ff-fe52-4d56-8525-a48aa6596af0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,437,226\n",
      "Trainable params: 1,437,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2BzZ4rWaLpN4",
    "outputId": "ccea9eb8-0d58-4989-edcc-937702deca71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 3, 32)\n",
      "(32,)\n",
      "(3, 3, 32, 32)\n",
      "(32,)\n",
      "(3, 3, 32, 64)\n",
      "(64,)\n",
      "(3, 3, 64, 64)\n",
      "(64,)\n",
      "(3, 3, 64, 128)\n",
      "(128,)\n",
      "(3, 3, 128, 128)\n",
      "(128,)\n",
      "(3, 3, 128, 256)\n",
      "(256,)\n",
      "(3, 3, 256, 256)\n",
      "(256,)\n",
      "(1024, 256)\n",
      "(256,)\n",
      "(256, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "t = model.get_weights()\n",
    "for v in t:\n",
    "  print(np.shape(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "b4Sk-U_jKoTm"
   },
   "outputs": [],
   "source": [
    "comms_round = 50\n",
    "loss='categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "optimizer = SGD(lr=0.01, \n",
    "                momentum=0.9\n",
    "               )   \n",
    "optimizer2 = SGD(lr=0.001,\n",
    "                 momentum=0.9\n",
    "               )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WYbxOUreCDai",
    "outputId": "f658b222-4dba-4556-c043-cb14e1767d3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 17 16:29:17 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   55C    P0    29W /  70W |    238MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Rxt1ZYW77GRn"
   },
   "outputs": [],
   "source": [
    "# model = MLP()\n",
    "# model = model.build()\n",
    "# model.compile(loss=loss, \n",
    "#                       optimizer=optimizer2, \n",
    "#                       metrics=metrics)\n",
    "# print((model.optimizer.lr))\n",
    "# model2 = MLP()\n",
    "# model2 = model2.build()\n",
    "# model2.compile(loss=loss, \n",
    "#                       optimizer=optimizer, \n",
    "#                       metrics=metrics)\n",
    "# print((model2.optimizer.lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "AOd6IRXnKsL8"
   },
   "outputs": [],
   "source": [
    "weight_scale = []\n",
    "for (name, data) in client_data.items():\n",
    "  weight_scale.append(len(data)/40000)\n",
    "weight_scale = np.array(weight_scale).reshape((len(weight_scale), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "RCUMQ1SkLY_B"
   },
   "outputs": [],
   "source": [
    "# def scale_model_weights(weight, scalar):\n",
    "#     weight_final = []\n",
    "#     steps = len(weight)\n",
    "#     for i in range(steps):\n",
    "#         weight_final.append(scalar * weight[i])\n",
    "#     return weight_final\n",
    "\n",
    "def sum_scaled_weights(scaled_weight_list, M, unlab_data):\n",
    "    #print(type(scaled_weight_list[0][0]))\n",
    "    temp = MLP()\n",
    "    model = temp.build()\n",
    "    p = np.zeros((10000,10))\n",
    "    for i in range(len(weight_scale)):\n",
    "      model.set_weights(scaled_weight_list[i])\n",
    "      p += model.predict(unlab_data)\n",
    "    avg_grad_mean = list()\n",
    "    avg_grad_var = list()\n",
    "    for grad_list_tuple in zip(*scaled_weight_list):\n",
    "        #print(np.shape(grad_list_tuple))\n",
    "        if len(np.shape(grad_list_tuple)) == 5:\n",
    "          w = weight_scale.reshape((len(weight_scale), 1, 1, 1, 1))\n",
    "        elif len(np.shape(grad_list_tuple)) == 4:\n",
    "          w = weight_scale.reshape((len(weight_scale), 1, 1, 1))\n",
    "        elif len(np.shape(grad_list_tuple)) == 3:\n",
    "          w = weight_scale.reshape((len(weight_scale), 1, 1))\n",
    "        else:\n",
    "          w = weight_scale\n",
    "        layer_mean = np.sum(grad_list_tuple*w, axis=0)\n",
    "        #print(np.shape(layer_mean))\n",
    "        layer_variance = np.sum(np.power(grad_list_tuple - layer_mean, 2)*w, axis = 0) \n",
    "        avg_grad_mean.append(layer_mean)\n",
    "        avg_grad_var.append(layer_variance)\n",
    "    model.set_weights(avg_grad_mean)\n",
    "    p += model.predict(unlab_data)\n",
    "    for i in range(M):\n",
    "      grad_list = list()\n",
    "      for j in range(len(avg_grad_var)):\n",
    "        grad_list.append(np.random.normal(avg_grad_mean[j], avg_grad_var[j]))\n",
    "      model.set_weights(grad_list)\n",
    "      p += model.predict(unlab_data)\n",
    "    return p/(M + len(weight_scale) + 1), avg_grad_mean\n",
    "\n",
    "\n",
    "def test_model(X_test, Y_test,  model, comm_round):\n",
    "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    logits = model.predict(X_test)\n",
    "    loss = cce(Y_test, logits)\n",
    "    acc = accuracy_score(tf.argmax(logits, axis=1), tf.argmax(Y_test, axis=1))\n",
    "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-qxqDSFM3LS",
    "outputId": "94240ad7-48fc-4f5f-f0eb-6a27945d512f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comm_round: 0 | global_acc: 16.070% | global_loss: 2.293994903564453\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0101s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "comm_round: 1 | global_acc: 32.890% | global_loss: 2.247204303741455\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0099s vs `on_train_batch_end` time: 0.0129s). Check your callbacks.\n",
      "comm_round: 2 | global_acc: 42.180% | global_loss: 2.1593682765960693\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0098s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "comm_round: 3 | global_acc: 47.020% | global_loss: 2.083404779434204\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0107s vs `on_train_batch_end` time: 0.0129s). Check your callbacks.\n",
      "comm_round: 4 | global_acc: 50.920% | global_loss: 2.0272583961486816\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0099s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "comm_round: 5 | global_acc: 53.750% | global_loss: 1.9874976873397827\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0097s vs `on_train_batch_end` time: 0.0131s). Check your callbacks.\n",
      "comm_round: 6 | global_acc: 56.180% | global_loss: 1.9557359218597412\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0115s vs `on_train_batch_end` time: 0.0129s). Check your callbacks.\n",
      "comm_round: 7 | global_acc: 58.640% | global_loss: 1.9266468286514282\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0102s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "comm_round: 8 | global_acc: 59.500% | global_loss: 1.9092808961868286\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0098s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "comm_round: 9 | global_acc: 61.350% | global_loss: 1.8875929117202759\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0097s vs `on_train_batch_end` time: 0.0131s). Check your callbacks.\n",
      "comm_round: 10 | global_acc: 62.510% | global_loss: 1.8732534646987915\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0095s vs `on_train_batch_end` time: 0.0127s). Check your callbacks.\n",
      "comm_round: 11 | global_acc: 63.480% | global_loss: 1.8596078157424927\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0104s vs `on_train_batch_end` time: 0.0128s). Check your callbacks.\n",
      "comm_round: 12 | global_acc: 64.810% | global_loss: 1.8482085466384888\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0103s vs `on_train_batch_end` time: 0.0129s). Check your callbacks.\n",
      "comm_round: 13 | global_acc: 65.710% | global_loss: 1.8365015983581543\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0113s vs `on_train_batch_end` time: 0.0126s). Check your callbacks.\n",
      "comm_round: 14 | global_acc: 66.490% | global_loss: 1.8291250467300415\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0100s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "comm_round: 15 | global_acc: 67.380% | global_loss: 1.8204644918441772\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0101s vs `on_train_batch_end` time: 0.0129s). Check your callbacks.\n",
      "comm_round: 16 | global_acc: 67.640% | global_loss: 1.8165308237075806\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0097s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "comm_round: 17 | global_acc: 68.170% | global_loss: 1.8113281726837158\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0103s vs `on_train_batch_end` time: 0.0129s). Check your callbacks.\n",
      "comm_round: 18 | global_acc: 68.730% | global_loss: 1.8053137063980103\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0098s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "comm_round: 19 | global_acc: 69.030% | global_loss: 1.800655484199524\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0098s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "comm_round: 20 | global_acc: 69.420% | global_loss: 1.7977524995803833\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0097s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "comm_round: 21 | global_acc: 69.700% | global_loss: 1.7942570447921753\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0098s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "comm_round: 22 | global_acc: 69.950% | global_loss: 1.790259599685669\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0102s vs `on_train_batch_end` time: 0.0129s). Check your callbacks.\n",
      "comm_round: 23 | global_acc: 70.540% | global_loss: 1.7874218225479126\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0097s vs `on_train_batch_end` time: 0.0127s). Check your callbacks.\n",
      "comm_round: 24 | global_acc: 70.200% | global_loss: 1.7877156734466553\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0098s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "comm_round: 25 | global_acc: 70.570% | global_loss: 1.7839784622192383\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0101s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "comm_round: 26 | global_acc: 70.780% | global_loss: 1.780055046081543\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0098s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "comm_round: 27 | global_acc: 70.960% | global_loss: 1.778212547302246\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0113s vs `on_train_batch_end` time: 0.0126s). Check your callbacks.\n",
      "comm_round: 28 | global_acc: 71.090% | global_loss: 1.7767810821533203\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0102s vs `on_train_batch_end` time: 0.0129s). Check your callbacks.\n",
      "comm_round: 29 | global_acc: 71.130% | global_loss: 1.7747564315795898\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0095s vs `on_train_batch_end` time: 0.0127s). Check your callbacks.\n",
      "comm_round: 30 | global_acc: 71.250% | global_loss: 1.7739012241363525\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0103s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "comm_round: 31 | global_acc: 71.480% | global_loss: 1.7716575860977173\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0101s vs `on_train_batch_end` time: 0.0128s). Check your callbacks.\n",
      "comm_round: 32 | global_acc: 71.680% | global_loss: 1.7701152563095093\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0099s vs `on_train_batch_end` time: 0.0129s). Check your callbacks.\n",
      "comm_round: 33 | global_acc: 71.780% | global_loss: 1.7690730094909668\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0098s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "comm_round: 34 | global_acc: 71.650% | global_loss: 1.768784761428833\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0095s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "comm_round: 35 | global_acc: 72.190% | global_loss: 1.7643479108810425\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0098s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "comm_round: 36 | global_acc: 72.010% | global_loss: 1.7644580602645874\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0099s vs `on_train_batch_end` time: 0.0128s). Check your callbacks.\n",
      "comm_round: 37 | global_acc: 72.380% | global_loss: 1.7628419399261475\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0096s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "comm_round: 38 | global_acc: 72.160% | global_loss: 1.7636473178863525\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0098s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "comm_round: 39 | global_acc: 72.170% | global_loss: 1.7623015642166138\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0106s vs `on_train_batch_end` time: 0.0126s). Check your callbacks.\n",
      "comm_round: 40 | global_acc: 72.610% | global_loss: 1.759919285774231\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0099s vs `on_train_batch_end` time: 0.0125s). Check your callbacks.\n",
      "comm_round: 41 | global_acc: 72.630% | global_loss: 1.7592945098876953\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0097s vs `on_train_batch_end` time: 0.0131s). Check your callbacks.\n",
      "comm_round: 42 | global_acc: 72.550% | global_loss: 1.7595622539520264\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0098s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "comm_round: 43 | global_acc: 72.730% | global_loss: 1.7577275037765503\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0097s vs `on_train_batch_end` time: 0.0127s). Check your callbacks.\n",
      "comm_round: 44 | global_acc: 72.740% | global_loss: 1.757422685623169\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0097s vs `on_train_batch_end` time: 0.0131s). Check your callbacks.\n",
      "comm_round: 45 | global_acc: 72.900% | global_loss: 1.7561453580856323\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0098s vs `on_train_batch_end` time: 0.0131s). Check your callbacks.\n",
      "comm_round: 46 | global_acc: 72.960% | global_loss: 1.756938099861145\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0098s vs `on_train_batch_end` time: 0.0126s). Check your callbacks.\n",
      "comm_round: 47 | global_acc: 73.030% | global_loss: 1.7557923793792725\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0097s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "comm_round: 48 | global_acc: 73.030% | global_loss: 1.755187749862671\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0097s vs `on_train_batch_end` time: 0.0130s). Check your callbacks.\n",
      "comm_round: 49 | global_acc: 73.030% | global_loss: 1.7542976140975952\n"
     ]
    }
   ],
   "source": [
    "mlp_global = MLP()\n",
    "global_model = mlp_global.build()\n",
    "\n",
    "for comm_round in range(comms_round):\n",
    "            \n",
    "    \n",
    "    global_weights = global_model.get_weights()\n",
    "    \n",
    "    \n",
    "    scaled_local_weight_list = list()\n",
    "    client_names = list(client_batched.keys())\n",
    "    random.shuffle(client_names)\n",
    "    \n",
    "    for client in client_names:\n",
    "        def scheduler(epoch, lr):\n",
    "            if epoch  == 8:\n",
    "              lr = lr*0.1\n",
    "            if epoch == 15:\n",
    "              lr = lr*0.1  \n",
    "            return lr\n",
    "        mlp_local = MLP()\n",
    "        local_model = mlp_local.build()\n",
    "        local_model.compile(loss=loss, \n",
    "                      optimizer=SGD(lr=0.01,momentum=0.9), \n",
    "                      metrics=metrics)\n",
    "        local_model.set_weights(global_weights)\n",
    "        \n",
    "        callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "        local_model.fit(client_batched[client], epochs=25, verbose=0, callbacks=[callback])\n",
    "        scaled_local_weight_list.append(local_model.get_weights())\n",
    "        \n",
    "        K.clear_session()\n",
    "    p, avg = sum_scaled_weights(scaled_local_weight_list, 10, unlab_dataset)\n",
    "    p = p**2/(np.sum(p**2, axis = 1).reshape((len(p), 1)))\n",
    "\n",
    "    lab_dataset = tf.data.Dataset.from_tensor_slices((unlab_img_data,p)).batch(128)\n",
    "    mlp_global = MLP()\n",
    "    global_model = mlp_global.build()\n",
    "    global_model.compile(loss=loss, \n",
    "                      optimizer=SGD(lr=0.001,momentum=0.9), \n",
    "                      metrics=metrics)\n",
    "    global_model.set_weights(avg)\n",
    "    swa = SWA(start_epoch=5, \n",
    "          lr_schedule='cyclic', \n",
    "          swa_lr=0.0004,\n",
    "          swa_lr2=0.001,\n",
    "          swa_freq=5,\n",
    "          verbose=0)\n",
    "    global_model.fit(lab_dataset, epochs = 20, verbose = 0, callbacks=[swa])\n",
    "\n",
    "    for(X_test, Y_test) in test_batched:\n",
    "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "NdEgGGUHw6sw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FedBE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
